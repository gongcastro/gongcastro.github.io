<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rstats on Gonzalo García-Castro</title>
    <link>http://gongcastro.github.io/tags/rstats/</link>
    <description>Recent content in rstats on Gonzalo García-Castro</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 05 Jul 2020 00:00:00 +0000</lastBuildDate><atom:link href="http://gongcastro.github.io/tags/rstats/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Importing data from multiple files simultaneously in R</title>
      <link>http://gongcastro.github.io/2020/07/05/importing-data-from-multiple-files-simultaneously-in-r/</link>
      <pubDate>Sun, 05 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>http://gongcastro.github.io/2020/07/05/importing-data-from-multiple-files-simultaneously-in-r/</guid>
      <description>TL;DRWe need to import several CSV or TXT files and merge them into one data frame in R. Regardless of what function we use to import the files, vectorising the operation using purrr::map in combination with do.call or dplyr::bind_rows is the most time-efficient method (~25 ms importing 50 files with 10,000 rows each), compared to for loops (~220ms) or using lapply (~123 ms). data.table::fread is the fastest function for importing data.</description>
    </item>
    
  </channel>
</rss>
